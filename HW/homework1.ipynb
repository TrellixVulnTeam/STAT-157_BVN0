{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Homework 1 - Berkeley STAT 157\n",
    "\n",
    "Handout 1/22/2017, due 1/29/2017 by 4pm in Git by committing to your repository. Please ensure that you add the TA Git account to your repository.\n",
    "\n",
    "1. Write all code in the notebook.\n",
    "1. Write all text in the notebook. You can use MathJax to insert math or generic Markdown to insert figures (it's unlikely you'll need the latter). \n",
    "1. **Execute** the notebook and **save** the results.\n",
    "1. To be safe, print the notebook as PDF and add it to the repository, too. Your repository should contain two files: ``homework1.ipynb`` and ``homework1.pdf``. \n",
    "\n",
    "The TA will return the corrected and annotated homework back to you via Git (please give `rythei` access to your repository)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T19:57:47.188990Z",
     "start_time": "2019-01-22T19:57:46.107420Z"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import ndarray as nd\n",
    "from mxnet import context\n",
    "import time\n",
    "import numpy as np\n",
    "def try_gpu(i):\n",
    "    if context.num_gpus() < i+1:\n",
    "        print('-'*20 + 'sorry, you can not use gpu' + '-'*20)\n",
    "        return context.cpu()\n",
    "    return context.gpu(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Speedtest for vectorization\n",
    "\n",
    "Your goal is to measure the speed of linear algebra operations for different levels of vectorization. You need to use `wait_to_read()` on the output to ensure that the result is computed completely, since NDArray uses asynchronous computation. Please see http://beta.mxnet.io/api/ndarray/_autogen/mxnet.ndarray.NDArray.wait_to_read.html for details. \n",
    "\n",
    "1. Construct two matrices $A$ and $B$ with Gaussian random entries of size $4096 \\times 4096$. \n",
    "1. Compute $C = A B$ using matrix-matrix operations and report the time. \n",
    "1. Compute $C = A B$, treating $A$ as a matrix but computing the result for each column of $B$ one at a time. Report the time.\n",
    "1. Compute $C = A B$, treating $A$ and $B$ as collections of vectors. Report the time.\n",
    "1. Bonus question - what changes if you execute this on a GPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(A, B, mul_type='matrix-matrix', context_type=context.cpu()):\n",
    "    n1, n2, n3 = A.shape[0], A.shape[1], B.shape[1]\n",
    "    C = nd.zeros((n1, n3), ctx=context_type)\n",
    "    tic = time.time()\n",
    "    \n",
    "    if mul_type == 'matrix-matrix':\n",
    "        C = nd.dot(A, B)\n",
    "    elif mul_type == 'matrix-vector':\n",
    "        for i in range(n3):\n",
    "            C[: , i] = nd.dot(A, B[: , i])\n",
    "    elif mul_type == 'vector-vector':\n",
    "        for i in range(n1):\n",
    "            for j in range(n3):\n",
    "                C[i][j] = nd.dot(A[i, : ], B[: , j])\n",
    "                \n",
    "    C.wait_to_read()\n",
    "    used_time = time.time() - tic\n",
    "    \n",
    "    return C, used_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute A*B with matrix-matrix: 0.000959\n",
      "compute A*B with matrix-vector: 0.031052\n",
      "compute A*B with vector-vector: 2.98823\n",
      "--------------------sorry, you can not use gpu--------------------\n",
      "compute A*B with matrix-matrix: 0.000105\n",
      "compute A*B with matrix-vector: 0.020026\n",
      "compute A*B with vector-vector: 2.92375\n"
     ]
    }
   ],
   "source": [
    "size = 100\n",
    "A_orignial = nd.random.randn(size, size)\n",
    "B_orignial = nd.random.randn(size, size)\n",
    "mul_types = ['matrix-matrix', 'matrix-vector', 'vector-vector']\n",
    "\n",
    "for use_gpu in [False, True]:\n",
    "    if use_gpu:\n",
    "        context_type = try_gpu(0)\n",
    "        A, B = A_orignial.copyto(context_type), B_orignial.copyto(context_type)\n",
    "    else:\n",
    "        context_type = context.cpu()\n",
    "        A, B = A_orignial, B_orignial\n",
    "        \n",
    "    for mul_type in mul_types:\n",
    "        C, used_time = matmul(A, B, mul_type=mul_type, context_type=context_type)\n",
    "        print('compute A*B with {0}: {1}'.format(mul_type, round(used_time, 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## 2. Semidefinite Matrices\n",
    "\n",
    "Assume that $A \\in \\mathbb{R}^{m \\times n}$ is an arbitrary matrix and that $D \\in \\mathbb{R}^{n \\times n}$ is a diagonal matrix with nonnegative entries. \n",
    "\n",
    "1. Prove that $B = A D A^\\top$ is a positive semidefinite matrix. \n",
    "1. When would it be useful to work with $B$ and when is it better to use $A$ and $D$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "1.证明：\n",
    "&\\because B^T = AD^TA^T = ADA^T = B\\\\\n",
    "&\\therefore B是对称矩阵\\\\\n",
    "&设x为任意非0向量，显然\\hat x=xA\\neq0\\\\\n",
    "&\\because D为非负对角矩阵\\\\\n",
    "&\\therefore \\hat xD\\hat x^T\\geq0,即xBx^T\\geq0\\\\\n",
    "&综上，B为半正定矩阵\n",
    "\\end{align}\t\n",
    "$$\t\t\t\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第2问参考答案：\n",
    "\n",
    "It would be more useful to work with B if m << n as matrix multiplication for instance for two arbitrary matrices X and Y with dimesnions a by b and b by c is a runtime of O(abc). If we multiply B by a matrix C that is m by k, then BC is computed in O(m2k). This matrix multiplication with ADATC is O(2mnk + n2k). Thus if m << n, then it would be more efficient to use B and if n >> m, then it would be better to use A and D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MXNet on GPUs\n",
    "\n",
    "1. Install GPU drivers (if needed)\n",
    "1. Install MXNet on a GPU instance\n",
    "1. Display `!nvidia-smi`\n",
    "1. Create a $2 \\times 2$ matrix on the GPU and print it. See http://d2l.ai/chapter_deep-learning-computation/use-gpu.html for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: nvidia-smi: command not found\n",
      "--------------------sorry, you can not use gpu--------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1. 1.]\n",
       " [1. 1.]]\n",
       "<NDArray 2x2 @cpu(0)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "x = nd.ones((2, 2), ctx=try_gpu(0))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. NDArray and NumPy \n",
    "\n",
    "Your goal is to measure the speed penalty between MXNet Gluon and Python when converting data between both. We are going to do this as follows:\n",
    "\n",
    "1. Create two Gaussian random matrices $A, B$ of size $4096 \\times 4096$ in NDArray. \n",
    "1. Compute a vector $\\mathbf{c} \\in \\mathbb{R}^{4096}$ where $c_i = \\|A B_{i\\cdot}\\|^2$ where $\\mathbf{c}$ is a **NumPy** vector.\n",
    "\n",
    "To see the difference in speed due to Python perform the following two experiments and measure the time:\n",
    "\n",
    "1. Compute $\\|A B_{i\\cdot}\\|^2$ one at a time and assign its outcome to $\\mathbf{c}_i$ directly.\n",
    "1. Use an intermediate storage vector $\\mathbf{d}$ in NDArray for assignments and copy to NumPy at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment 1 used time: 0.4060671329498291\n",
      "experiment 2 used time; 0.2716867923736572\n"
     ]
    }
   ],
   "source": [
    "def exp_1(A, B):\n",
    "    n = A.shape[0]\n",
    "    c = np.zeros(n)\n",
    "    tic = time.time()\n",
    "    for i in range(n):\n",
    "        c[i] = np.linalg.norm(np.dot(A.asnumpy(), B[: , i].asnumpy()))\n",
    "        #c[i] = (nd.norm(nd.dot(A, B[: , i])).asscalar())**2\n",
    "    return c, time.time()-tic\n",
    "\n",
    "def exp_2(A, B):\n",
    "    n = A.shape[0]\n",
    "    c = nd.zeros(n)\n",
    "    tic = time.time()\n",
    "    for i in range(n):\n",
    "        c[i] = (nd.norm(nd.dot(A, B[: , i])))**2\n",
    "    c = c.asnumpy()\n",
    "    return c, time.time()-tic\n",
    "size = 1000\n",
    "A, B = nd.random.randn(size, size), nd.random.randn(size, size)\n",
    "_, used_time1 = exp_1(A, B)\n",
    "_, used_time2 = exp_2(A, B)\n",
    "print('experiment 1 used time: {0}\\nexperiment 2 used time; {1}'.format(used_time1, used_time2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不是很理解上面的问题，如果按照自己的做法，可以看出从NDarray转化到np.array是会花费不少代价的\n",
    "\n",
    "看完答案后没有解释这题的目的，不过答案用的是上面注释掉的代码，另外在网上看到一个[链接](https://mxnet.incubator.apache.org/versions/master/tutorials/python/profiler.html)，关于NDarray转化到np.array，以及刻画模型运行指标的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Memory efficient computation\n",
    "\n",
    "We want to compute $C \\leftarrow A \\cdot B + C$, where $A, B$ and $C$ are all matrices. Implement this in the most memory efficient manner. Pay attention to the following two things:\n",
    "\n",
    "1. Do not allocate new memory for the new value of $C$.\n",
    "1. Do not allocate new memory for intermediate results if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nd.ones((10, 10))\n",
    "B = nd.ones((10, 10))\n",
    "C = nd.ones((10, 10))\n",
    "C += nd.dot(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Broadcast Operations\n",
    "\n",
    "In order to perform polynomial fitting we want to compute a design matrix $A$ with \n",
    "\n",
    "$$A_{ij} = x_i^j$$\n",
    "\n",
    "Our goal is to implement this **without a single for loop** entirely using vectorization and broadcast. Here $1 \\leq j \\leq 20$ and $x = \\{-10, -9.9, \\ldots 10\\}$. Implement code that generates such a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.50812554 -1.2068808   1.2174315   0.13453278 -0.7020151  -2.2163332\n",
       "  -0.48276684  0.5110155  -1.6071362  -2.9807727 ]\n",
       " [ 0.50812554 -1.2068808   1.2174315   0.13453278 -0.7020151  -2.2163332\n",
       "  -0.48276684  0.5110155  -1.6071362  -2.9807727 ]\n",
       " [ 0.50812554 -1.2068808   1.2174315   0.13453278 -0.7020151  -2.2163332\n",
       "  -0.48276684  0.5110155  -1.6071362  -2.9807727 ]\n",
       " [ 0.50812554 -1.2068808   1.2174315   0.13453278 -0.7020151  -2.2163332\n",
       "  -0.48276684  0.5110155  -1.6071362  -2.9807727 ]\n",
       " [ 0.50812554 -1.2068808   1.2174315   0.13453278 -0.7020151  -2.2163332\n",
       "  -0.48276684  0.5110155  -1.6071362  -2.9807727 ]\n",
       " [ 0.50812554 -1.2068808   1.2174315   0.13453278 -0.7020151  -2.2163332\n",
       "  -0.48276684  0.5110155  -1.6071362  -2.9807727 ]\n",
       " [ 0.50812554 -1.2068808   1.2174315   0.13453278 -0.7020151  -2.2163332\n",
       "  -0.48276684  0.5110155  -1.6071362  -2.9807727 ]\n",
       " [ 0.50812554 -1.2068808   1.2174315   0.13453278 -0.7020151  -2.2163332\n",
       "  -0.48276684  0.5110155  -1.6071362  -2.9807727 ]\n",
       " [ 0.50812554 -1.2068808   1.2174315   0.13453278 -0.7020151  -2.2163332\n",
       "  -0.48276684  0.5110155  -1.6071362  -2.9807727 ]\n",
       " [ 0.50812554 -1.2068808   1.2174315   0.13453278 -0.7020151  -2.2163332\n",
       "  -0.48276684  0.5110155  -1.6071362  -2.9807727 ]]\n",
       "<NDArray 10x10 @cpu(0)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nd.ones((10, 1))\n",
    "y = nd.random.randn(1, 10)\n",
    "(y**x)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
